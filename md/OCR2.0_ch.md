# 引领光学字符识别（OCR）的新篇章

## 引言：OCR技术进化的必要性
光学字符识别（OCR）是一项广泛应用的技术，它能够从图像中提取字符并将其转换为可编辑格式。虽然OCR-1.0在过去取得了广泛应用，但传统的系统在处理现代复杂任务方面遇到了很多挑战，包括文档、复杂图表以及乐谱等多种文本格式的处理。本文讨论了OCR技术的进化方向，重点介绍了通用OCR理论（General OCR Theory）以及新提出的GOT模型。

## OCR-1.0的局限性
传统的OCR系统通常采用多模块流水线式的架构，包括元素检测、区域裁剪和字符识别。然而，这种模块化方式存在显著的缺陷，如局部最优问题、高维护成本以及缺乏通用性。传统OCR方法往往针对特定任务进行优化，可能适合处理文档OCR，但在场景文本或结构化数据任务中表现不佳，用户需要频繁切换模型。

## OCR-2.0的愿景
随着智能光学字符处理需求的不断增长，OCR-2.0应运而生。新的理论强调一个统一的、端到端的模型，能够在同一个框架内处理多种字符形式，包括文本、图表、几何图形，甚至乐谱。为此，作者提出了通用光学字符识别理论（General Optical Character Recognition Theory, OCR-2.0）及其核心模型GOT（General Optical Text）。

GOT模型引入了高压缩率的编码器和长上下文解码器，使得GOT能够在多种OCR任务中表现出色。GOT模型具有端到端结构，计算成本低，且具备强大的通用性，能够处理英文和中文文本，并支持用户交互，如通过坐标或颜色进行区域识别。

## GOT模型：统一的OCR解决方案
GOT采用了编码器-解码器架构，专为应对现代OCR任务而设计。编码器将输入图像压缩为一系列token，而解码器则将这些token转换为文本或结构化输出。GOT的编码器约有8000万参数，能够处理高分辨率输入（如整页文档），解码器则有5亿参数，支持长上下文场景，使得它在需要识别大量文本的文档处理任务中表现尤为出色。

该模型的高压缩比使其即便在消费级GPU上也能高效运行，相较传统OCR系统的高硬件要求，GOT无疑具有更大的优势。


## Framework
![alt text](image-4.png)
这一部分介绍了OCR-2.0系统的核心架构和优化策略。GOT模型的整体设计包含了三个模块，分别是图像编码器、线性层和解码器。通过这三大模块的协同工作，GOT模型能够高效地处理各种OCR任务。

首先，预训练视觉编码器时，通过选择小型解码器和适当的数据输入，确保模型在提高效率的同时不会浪费GPU资源。在此过程中，系统通过学习常见的文本编码特征，提升了对常用字符的处理能力。

接着，模型进入第二阶段，将已经训练好的视觉编码器连接到新的更大解码器。这一步骤不仅仅是扩大模型容量，更重要的是通过增加多种数据类型如乐谱、数学公式和几何图形来丰富模型的应用范围，从而扩展了GOT的知识库。

最后，通过细粒度的数据和多页面合成数据，进一步增强了模型的泛化能力，使其在处理不同类型的OCR任务时表现更为出色。GOT能够处理区域提示OCR、超大图像OCR和批量PDF OCR，这意味着它不仅仅适用于传统的文本识别，还可以处理更加复杂和多样化的光学字符识别任务。

总的来说，GOT模型为OCR技术的发展提供了一个完整的、统一的解决方案，具备出色的多任务处理能力。


## 创新的训练策略

GOT的训练过程分为三个阶段：
1. **编码器预训练**：首先对GOT的视觉编码器进行预训练，处理场景文本和文档样式图像，通过全页文档和文本片段的组合，使编码器能够适应不同的输入格式。
2. **联合训练**：预训练完成后，编码器与更大的语言解码器连接，扩展GOT的OCR能力，以处理更复杂的字符，如数学公式和图表。
3. **解码器后期训练**：最后阶段是对解码器进行微调，增加对多页文档处理、细粒度区域OCR以及高分辨率图像的支持。




## 数据生成助力OCR-2.0
GOT成功的关键在于其合成数据的生成。在预训练阶段，使用了约500万对图像-文本数据，包括英文和中文的数据集。为进一步增强其能力，还生成了诸如数学公式、分子结构和几何图形等特定任务的合成数据。这些数据的加入使得GOT的OCR-2.0知识得到了显著扩展，确保其在各种应用中的通用性。

## OCR-2.0的实际应用：性能与结果
GOT模型在多个OCR任务中表现优异：

1. **文档OCR**：GOT在中英文PDF文档OCR任务中表现突出，精确度超过了多款OCR模型，展现了出色的文档文本感知与识别能力。
2. **场景文本OCR**：在自然场景图像中，GOT也同样表现出色，进一步证明了其多任务处理能力。
3. **格式化OCR**：GOT能够将光学PDF图像转换为结构化的输出格式（如Markdown格式），特别适用于学术和技术文档。
4. **细粒度OCR**：GOT具备交互式OCR功能，用户可以指定感兴趣的区域进行文字提取，这在精确性方面表现优异。
5. **通用OCR**：除了文本，GOT还能够识别更加复杂的光学字符，如几何图形、乐谱，甚至是图表，展现了更广泛的适用性。

### GOT模型在场景文本OCR任务中的表现

![alt text](image-5.png)

在表2中，展示了不同模型在场景文本OCR任务中的性能表现。这些模型包括了从UReader到GOT在内的多种最新OCR技术。表中的性能指标涵盖了编辑距离（Edit Distance）、F1分数、精度（Precision）、召回率（Recall）、BLEU分数和METEOR分数等。

### 性能对比：
- **GOT模型的优势**：GOT模型以580M参数的规模，表现出优异的性能，尤其是在英文和中文的场景文本OCR任务中均获得了最高的F1分数（0.926 en，0.928 zh）。此外，GOT在精度和召回率方面也领先于其他模型，分别达到了0.934和0.927（en），以及0.914和0.954（zh）。
- **编辑距离**：GOT的编辑距离为0.112（en）和0.096（zh），远远优于其他较大的模型，如Qwen-VL-Max (>72B参数) 和InternVL-ChatV1.5 (26B参数)。
- **综合评价**：从BLEU和METEOR分数来看，GOT在中英文的表现也十分强劲，特别是在METEOR得分方面，GOT的分数分别为0.896（en）和0.928（zh），显示了极高的文本质量预测能力。


收集了400张自然场景图像，分别为200张中文图像和200张英文图像，作为场景文本OCR的基准数据集。该数据集中的所有真实标签均通过人工校正。在这些场景文本图像中，文本相对较短，因此使用字符级别的分割来计算各项指标。

从表2可以看出，GOT在处理自然场景图像时也表现出色，证明了其在大多数基本OCR任务（包括文档和场景文本）的卓越性能。特别是对于复杂的场景文本，GOT模型的表现无论是在英文还是中文任务中，均遥遥领先于其他较大规模的模型。

## 结论：迈向OCR的新纪元
通用OCR理论和GOT模型代表了OCR技术的一次重大飞跃。OCR-2.0抛弃了过去碎片化、任务特定的OCR模型，提出了一种更统一、高效、通用的字符识别方式。无论是处理密集的文档文本，还是复杂的结构化数据，GOT在各个领域的出色表现为未来OCR创新铺平了道路。

这款统一的模型在多个行业中展现出巨大的潜力，从学术研究到法律文件处理，GOT无疑是通向下一代OCR技术的关键一步。











# 3.2 预训练OCR指定的视觉编码器

GOT模型采用了编码器-解码器架构，受LVLMs设计启发，解码器可以通过预训练的语言模型进行初始化。然而，由于没有合适的OCR-2.0编码器可供使用，我们必须自行训练一个新的编码器，期望它能在不同输入形状下（切片和整页）表现出色的场景文本和文档识别能力。

## 3.2.1 视觉编码器生成

我们选择了VitDet架构（基于80M参数）作为编码器，由于其局部注意力机制可以极大地减少高分辨率图像的计算成本。我们使用Vary-tiny设置，将1024×1024×3输入图像转换为256×1024的图像tokens，然后通过1024×768的线性层投射到OPT-125M的维度。与只处理单一文档任务的Vary编码器不同，我们在预训练过程中加入了自然场景和裁剪切片。预处理阶段中，所有形状的图像被统一调整为1024×1024的正方形，以适应各种纵横比的图像。

## 3.2.2 编码器预训练的数据引擎

在编码器预训练阶段，我们使用了大约500万对图像-文本对数据，包括300万场景文本OCR数据和200万文档OCR数据。具体的数据获取方法如下：

- **自然场景数据**：我们从Laion-2B和Wukong数据集中采样英文和中文图像，使用PaddleOCR工具捕获伪真实标签，总共获取了200万张数据，其中50%为中文，50%为英文。我们进行了两种处理：1）去除边界框，按从上到下、从左到右的顺序组合文本内容；2）根据边界框从原始图像中裁剪文本区域并保存为图像切片。这第二种方法使我们额外获得了100万对切片类型的图像-文本对。

- **文档级数据**：我们首先从Common Crawl收集了开源PDF文件，使用Fitz Python包提取了对应的密集文本内容。在这个过程中，我们获得了120万对完整PDF页面的图像-文本对以及80万对图像切片数据。这些切片数据包括行级和段落级，均通过解析的边界框从PDF图像中裁剪而来。
